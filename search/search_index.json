{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Whisper ASR Webservice","text":"<p>Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitask model that can perform multilingual speech recognition as well as speech translation and language identification.</p>"},{"location":"#features","title":"Features","text":"<p>Current release (v1.4.1) supports following whisper models:</p> <ul> <li>openai/whisper@v20231117</li> <li>SYSTRAN/faster-whisper@v0.10.0</li> </ul>"},{"location":"#quick-usage","title":"Quick Usage","text":"<code>CPU</code> <code>GPU</code> <pre><code>docker run -d -p 9000:9000 -e ASR_MODEL=base -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre> <pre><code>docker run -d --gpus all -p 9000:9000 -e ASR_MODEL=base -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest-gpu\n</code></pre> <p>for more information:</p> <ul> <li>Documentation/Run</li> <li>Docker Hub</li> </ul>"},{"location":"#credits","title":"Credits","text":"<ul> <li>This software uses libraries from the FFmpeg project under the LGPLv2.1</li> </ul>"},{"location":"build/","title":"Build","text":""},{"location":"build/#development-environment","title":"Development Environment","text":"<p>Install poetry with following command:</p> <pre><code>pip3 install poetry\n</code></pre> <p>Install torch with following command:</p> <pre><code># just for GPU:\npip3 install torch==1.13.1+cu117 -f https://download.pytorch.org/whl/torch\n</code></pre>"},{"location":"build/#run","title":"Run","text":"<p>Install packages:</p> <pre><code>poetry install\n</code></pre> <p>Starting the Webservice:</p> <pre><code>poetry run gunicorn --bind 0.0.0.0:9000 --workers 1 --timeout 0 app.webservice:app -k uvicorn.workers.UvicornWorker\n</code></pre>"},{"location":"build/#build","title":"Build","text":"<code>Poetry</code> <code>Docker</code> <p>Build .whl package</p> <pre><code>poetry build\n</code></pre> <p>With <code>Dockerfile</code>:</p> <code>CPU</code> <code>GPU</code> <pre><code># Build Image\ndocker build -t whisper-asr-webservice .\n\n# Run Container\ndocker run -d -p 9000:9000 whisper-asr-webservice\n# or\ndocker run -d -p 9001:9000 -e ASR_MODEL=base whisper-asr-webservice3\n</code></pre> <pre><code># Build Image\ndocker build -f Dockerfile.gpu -t whisper-asr-webservice-gpu .\n\n# Run Container\ndocker run -d --gpus all -p 9000:9000 whisper-asr-webservice-gpu\n# or\ndocker run -d --gpus all -p 9000:9000 -e ASR_MODEL=base whisper-asr-webservice-gpu\n</code></pre> <p>With <code>docker-compose</code>:</p> <code>CPU</code> <code>GPU</code> <pre><code>docker-compose up --build\n</code></pre> <pre><code>docker-compose up --build -f docker-compose.gpu.yml\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#141-2024-04-17","title":"1.4.1 (2024-04-17)","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Upgraded torch to v1.13.1</li> </ul>"},{"location":"changelog/#140-2024-04-17","title":"1.4.0 (2024-04-17)","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Upgraded<ul> <li>SYSTRAN/faster-whisper to v1.0.1</li> <li>fastapi to v0.110.1</li> <li>uvicorn to v0.29.0</li> <li>gunicorn to v21.2.0</li> <li>tqdm to v4.66.2</li> <li>python-multipart to v0.0.9</li> <li>llvmlite to v0.42.0</li> <li>numba to v0.59.1</li> </ul> </li> </ul>"},{"location":"changelog/#130-2024-02-15","title":"1.3.0 (2024-02-15)","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Compiled and added FFmpeg without LGPL libraries for license compliance</li> </ul>"},{"location":"changelog/#124-2023-11-27","title":"1.2.4 (2023-11-27)","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Upgraded<ul> <li>openai/whisper to v20231117</li> <li>SYSTRAN/faster-whisper to v0.10.0</li> </ul> </li> </ul>"},{"location":"changelog/#123-2023-11-07","title":"1.2.3 (2023-11-07)","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Upgraded<ul> <li>openai/whisper to v20231106</li> </ul> </li> </ul>"},{"location":"changelog/#122-2023-11-03","title":"1.2.2 (2023-11-03)","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed <code>swagger-ui</code> rendering issues by upgrading to <code>v5.9.1</code>, fixes #153 and #154</li> </ul>"},{"location":"changelog/#121-2023-11-03","title":"1.2.1 (2023-11-03)","text":""},{"location":"changelog/#enabled","title":"Enabled","text":"<ul> <li>Enabled <code>vad_filter</code> for <code>faster-whisper</code> engine</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Changed misspelling in \"Word level timestamps\"</li> <li>Removed unused unidecode dependency</li> <li>Upgraded<ul> <li>uvicorn to v0.23.2</li> <li>gunicorn to v21.0.1</li> <li>tqdm to v4.66.1</li> <li>python-multipart to v0.0.6</li> <li>fastapi to v0.104.1</li> <li>llvmlite to v0.41.1</li> <li>numba to v0.58.0</li> </ul> </li> </ul>"},{"location":"changelog/#120-2023-10-01","title":"1.2.0 (2023-10-01)","text":""},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Upgraded<ul> <li>openai/whisper to v20230918</li> <li>guillaumekln/faster-whisper to v0.9.0</li> </ul> </li> </ul>"},{"location":"changelog/#updated","title":"Updated","text":"<ul> <li>Updated model conversion method (for Faster Whisper) to use Hugging Face downloader</li> <li>Updated default model paths to <code>~/.cache/whisper</code> or <code>/root/.cache/whisper</code>.<ul> <li>For customization, modify the <code>ASR_MODEL_PATH</code> environment variable.</li> <li>Ensure Docker volume is set for the corresponding directory to use caching.   <pre><code>docker run -d -p 9000:9000 -e ASR_MODEL_PATH=/data/whisper -v $PWD/yourlocaldir:/data/whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre></li> </ul> </li> <li>Removed the <code>triton</code> dependency from <code>poetry.lock</code> to ensure the stability of the pipeline for <code>ARM-based</code> Docker images</li> </ul>"},{"location":"changelog/#111-2023-05-29","title":"1.1.1 (2023-05-29)","text":""},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>94 gpus that don't support float16 in #103</li> <li>Update compute type in #108</li> <li>Add word level functionality for Faster Whisper in #109</li> </ul>"},{"location":"changelog/#110-2023-04-17","title":"1.1.0 (2023-04-17)","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>Docs in #72</li> <li>Fix language code typo in #77</li> <li>Adds support for FasterWhisper in #81</li> <li>Add an optional param to skip the encoding step in #82</li> <li>Faster whisper in #92</li> </ul>"},{"location":"changelog/#106-2023-02-05","title":"1.0.6 (2023-02-05)","text":""},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li>Update README.md in #58</li> <li>68 update the versions in #69</li> <li>Fix gunicorn run command and remove deprecated poetry run script in #70</li> <li>Move torch installation method into the pyproject.toml file in #71</li> <li>Add prompt to ASR in #66</li> </ul>"},{"location":"changelog/#105-2022-12-08","title":"1.0.5 (2022-12-08)","text":""},{"location":"changelog/#changed_9","title":"Changed","text":"<ul> <li>43 make swagger doc not depend on internet connection in #52</li> <li>Add new large model v2 in #53</li> </ul>"},{"location":"changelog/#104-2022-11-28","title":"1.0.4 (2022-11-28)","text":""},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>43 make swagger doc not depend on internet connection in #51</li> <li>Anally retentively fixed markdown linting warnings in README. Sorry. in #48</li> <li>Explicit macOS readme with explanation for no-GPU [closes #44] in #47</li> </ul>"},{"location":"changelog/#103-beta-2022-11-17","title":"1.0.3-beta (2022-11-17)","text":""},{"location":"changelog/#changed_11","title":"Changed","text":"<ul> <li>Combine transcribe endpoints in #36</li> <li>Add multi worker support with gunicorn in #37</li> <li>Add multi platform (amd &amp; arm) support in #39</li> <li>Upgrade Cuda version to 11.7 in #40</li> <li>Lock to the latest whisper version (eff383) in #41</li> </ul>"},{"location":"changelog/#102-beta-2022-10-04","title":"1.0.2-beta (2022-10-04)","text":""},{"location":"changelog/#changed_12","title":"Changed","text":"<ul> <li>add mutex lock to the model in #19</li> <li>Subtitles in #21</li> <li>Add gpu support and create Docker image for cuda with GitHub flow in #22</li> </ul>"},{"location":"changelog/#101-beta-2022-09-27","title":"1.0.1-beta (2022-09-27)","text":""},{"location":"changelog/#changed_13","title":"Changed","text":"<ul> <li>Init GitHub runners in #10</li> <li>Lock Whisper dependency with b4308... revision number to prevent build crashes in #15</li> </ul>"},{"location":"changelog/#100-beta-2022-09-25","title":"1.0.0-beta (2022-09-25)","text":""},{"location":"changelog/#changed_14","title":"Changed","text":"<ul> <li>Docker init in #1</li> <li>Create LICENCE in #2</li> <li>Fastapi init in #3</li> <li>Avoid temp file in #4</li> <li>Translate init in #5</li> <li>mp3 support by using FFmpeg instead of librosa in #8</li> <li>add language detection endpoint in #9</li> </ul>"},{"location":"endpoints/","title":"Endpoints","text":""},{"location":"endpoints/#quick-start","title":"Quick start","text":"<p>After running the docker image interactive Swagger API documentation is available at localhost:9000/docs</p> <p>There are 2 endpoints available:</p> <ul> <li>/asr (Automatic Speech Recognition)</li> <li>/detect-language</li> </ul>"},{"location":"endpoints/#automatic-speech-recognition-service-asr","title":"Automatic speech recognition service /asr","text":"<ul> <li>2 task choices:</li> <li>transcribe: (default) task, transcribes the uploaded file.</li> <li>translate: will provide an English transcript no matter which language was spoken.</li> <li>Files are automatically converted with FFmpeg.</li> <li>Full list of supported audio and video formats.</li> <li>You can enable word level timestamps output by <code>word_timestamps</code> parameter</li> <li>You can Enable the voice activity detection (VAD) to filter out parts of the audio without speech  by <code>vad_filter</code> parameter (only with <code>Faster Whisper</code> for now).</li> </ul>"},{"location":"endpoints/#request-url-query-params","title":"Request URL Query Params","text":"Name Values audio_file File output <code>text</code> (default), <code>json</code>, <code>vtt</code>, <code>strt</code>, <code>tsv</code> task <code>transcribe</code>, <code>translate</code> language <code>en</code> (default is auto recognition) word_timestamps false (default) encode true (default) <p>Example request with cURL <pre><code>curl -X POST -H \"content-type: multipart/form-data\" -F \"audio_file=@/path/to/file\" 0.0.0.0:9000/asr?output=json\n</code></pre></p>"},{"location":"endpoints/#response-json","title":"Response (JSON)","text":"<ul> <li>text: Contains the full transcript</li> <li>segments: Contains an entry per segment. Each entry provides <code>timestamps</code>, <code>transcript</code>, <code>token ids</code>, <code>word level timestamps</code> and other metadata</li> <li>language: Detected or provided language (as a language code)</li> </ul>"},{"location":"endpoints/#language-detection-service-detect-language","title":"Language detection service /detect-language","text":"<p>Detects the language spoken in the uploaded file. Only processes first 30 seconds.</p> <p>Returns a json with following fields:</p> <ul> <li>detected_language: \"english\"</li> <li>language_code: \"en\"</li> </ul>"},{"location":"environmental-variables/","title":"Environmental Variables","text":""},{"location":"environmental-variables/#configuring-the-engine","title":"Configuring the <code>Engine</code>","text":"<code>openai_whisper</code> <code>faster_whisper</code> <pre><code>export ASR_ENGINE=openai_whisper\n</code></pre> <pre><code>export ASR_ENGINE=faster_whisper\n</code></pre>"},{"location":"environmental-variables/#configuring-the-model","title":"Configuring the <code>Model</code>","text":"<pre><code>export ASR_MODEL=base\n</code></pre> <p>Available ASR_MODELs are <code>tiny</code>, <code>base</code>, <code>small</code>, <code>medium</code>, <code>large</code> (only OpenAI Whisper), <code>large-v1</code>, <code>large-v2</code> and <code>large-v3</code>.</p> <p>For English-only applications, the <code>.en</code> models tend to perform better, especially for the <code>tiny.en</code> and <code>base.en</code> models. We observed that the difference becomes less significant for the <code>small.en</code> and <code>medium.en</code> models.</p>"},{"location":"environmental-variables/#configuring-the-model-path","title":"Configuring the <code>Model Path</code>","text":"<pre><code>export ASR_MODEL_PATH=/data/whisper\n</code></pre>"},{"location":"licence/","title":"Licence","text":"<pre><code>MIT License\n\nCopyright (c) 2022 Ahmet Oner &amp; Besim Alibegovic\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"run/","title":"Run","text":""},{"location":"run/#usage","title":"Usage","text":"<p>Whisper ASR Webservice now available on Docker Hub. You can find the latest version of this repository on docker hub for CPU and GPU.</p> <p>Docker Hub: https://hub.docker.com/r/onerahmet/openai-whisper-asr-webservice</p> <code>CPU</code> <code>CPU (macOS)</code> <code>GPU</code> <pre><code>docker pull onerahmet/openai-whisper-asr-webservice:latest\ndocker run -d -p 9000:9000 -e ASR_MODEL=base -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre> <p>GPU passthrough does not work on macOS due to fundamental design limitations of Docker. Docker actually runs containers within a LinuxVM on macOS. If you wish to run GPU-accelerated containers, I'm afraid Linux is your only option.</p> <p>The <code>:latest</code> image tag provides both amd64 and arm64 architectures:</p> <pre><code>docker pull onerahmet/openai-whisper-asr-webservice:latest\ndocker run -d -p 9000:9000 -e ASR_MODEL=base -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre> <pre><code>docker pull onerahmet/openai-whisper-asr-webservice:latest-gpu\ndocker run -d --gpus all -p 9000:9000 -e ASR_MODEL=base -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest-gpu\n</code></pre> <p>Interactive Swagger API documentation is available at http://localhost:9000/docs</p> <p></p>"},{"location":"run/#cache","title":"Cache","text":"<p>The ASR model is downloaded each time you start the container, using the large model this can take some time.  If you want to decrease the time it takes to start your container by skipping the download, you can store the cache directory (<code>~/.cache/whisper</code> or <code>/root/.cache/whisper</code>) to a persistent storage.  Next time you start your container the ASR Model will be taken from the cache instead of being downloaded again.</p> <p>Important this will prevent you from receiving any updates to the models.</p> <code>Default cache dir</code> <code>With ASR_MODEL_PATH</code> <pre><code>docker run -d -p 9000:9000 -v $PWD/yourlocaldir:/root/.cache/whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre> <pre><code>docker run -d -p 9000:9000 -e ASR_MODEL_PATH=/data/whisper -v $PWD/yourlocaldir:/data/whisper onerahmet/openai-whisper-asr-webservice:latest\n</code></pre>"}]}